{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Soyabean_final.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcrlIhMbRwOS"
      },
      "source": [
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd\n",
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import initializers\n",
        "from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dPUFQHp-Tlsj"
      },
      "source": [
        "def load_data(x): # flag 1 for training data, 0 for testing data\n",
        "    drct = r\"../data/TrainDataC2/\" \n",
        "    \n",
        "    imgL = []\n",
        "    if x:\n",
        "        df = pd.read_csv('../data/TrainAnnotations.csv')  \n",
        "        for i in range(len(df.annotation)):\n",
        "\n",
        "            name = str(df.file_name[i])      # read the file name from the annotation csv\n",
        "            path = drct+name\n",
        "            img = cv2.imread(path)           # Read the corresponding image\n",
        "            img = cv2.resize(img,(224,224))  # Resize all images to (224, 224) \n",
        "            imgL.append(img) \n",
        "\n",
        "        data = np.array(imgL)                # Convert list of images to numpy array\n",
        "        clas = df.annotation.values  \n",
        "        return data, clas                    # return images and class labels\n",
        "\n",
        "    else: \n",
        "        img_dir = \"../data/TestData\" # Enter Directory of test images \n",
        "        data_path = os.path.join(img_dir,'*g')\n",
        "        files = glob.glob(data_path)\n",
        "        data=[]\n",
        "        for f1 in files: \n",
        "          img = cv2.imread(f1)               # Read the image in the test directory\n",
        "          img = cv2.resize(img,(224,224))    # Resize the image \n",
        "          data.append(img)   \n",
        "        data = np.array(data)\n",
        "        return data                          # Return the array of test images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cV6O4Q_-RwOd"
      },
      "source": [
        "x_train, y_train =  load_data(1)\r\n",
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQQ2avM1nJok"
      },
      "source": [
        "x_test = load_data(0)\r\n",
        "x_test.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IFtczRPlRwOg"
      },
      "source": [
        "def get_dir(x,y):\n",
        "    d_dir = {0:[],1:[],2:[],3:[],4:[]}\n",
        "\n",
        "    for i in range(len(y)):\n",
        "        for c in range(5):\n",
        "            if y[i] == c: \n",
        "                d_dir[c].append(x[i])\n",
        "                break\n",
        "    return d_dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4qrJqZnmWjuh"
      },
      "source": [
        "def augment(image_arr, d):\r\n",
        "    aug_list = np.ndarray(image_arr.shape[1:])\r\n",
        "    aug_list = np.expand_dims(aug_list, axis=0)\r\n",
        "\r\n",
        "    for i in range(d//4):\r\n",
        "\r\n",
        "      image = image_arr[i]                              # Read the image \r\n",
        "      flipped = tf.image.flip_left_right(image)         # Flip the image across verticle axis\r\n",
        "      saturated = tf.image.adjust_saturation(image, 2)  # Add color saturation to the image\r\n",
        "      bright = tf.image.adjust_brightness(image, 0.1)   # Add brightness to the image\r\n",
        "      rotated = tf.image.rot90(image)                   # Rotate the image 90 dec right\r\n",
        "      \r\n",
        "      aug_list = np.vstack((aug_list, np.expand_dims(flipped, axis=0)))\r\n",
        "      aug_list = np.vstack((aug_list, np.expand_dims(saturated, axis=0)))\r\n",
        "      aug_list = np.vstack((aug_list, np.expand_dims(bright, axis=0)))\r\n",
        "      aug_list = np.vstack((aug_list, np.expand_dims(rotated, axis=0)))\r\n",
        "\r\n",
        "    return aug_list"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xU5mGdS1pdqi"
      },
      "source": [
        "# creating balanced validation dataset\r\n",
        "splitList = [0.08, 0.12, 0.31, 0.30, 0.20]   # Fraction of each class to get balanced validation set\r\n",
        "data_dir = get_dir(x_train, y_train)\r\n",
        "\r\n",
        "for i in range(len(splitList)):\r\n",
        "  data = np.array(data_dir[i])\r\n",
        "  label = i*np.ones((len(data)))\r\n",
        "  train_X, test_X, train_y, test_y = train_test_split(data, label, test_size=splitList[i])\r\n",
        "\r\n",
        "  # No augmentation for class zero\r\n",
        "  if i == 0:\r\n",
        "    train_data = train_X\r\n",
        "    train_label = train_y\r\n",
        "    val_data = test_X\r\n",
        "    val_label = test_y\r\n",
        "\r\n",
        "  # Augmentation for class 1, 2, 3 and 4\r\n",
        "  else:\r\n",
        "    d = len(data_dir[0]) - len(data_dir[i])\r\n",
        "    aug = augment(train_X, d)\r\n",
        "    print(\"Difference: {} | Images augmented: {}\".format(d, aug.shape[0]))\r\n",
        "\r\n",
        "    train_data = np.vstack((train_data, train_X))\r\n",
        "    train_data = np.vstack((train_data, aug))\r\n",
        "    train_label = np.hstack((train_label, train_y))\r\n",
        "    train_label = np.hstack((train_label, i*np.ones((aug.shape[0],))))\r\n",
        "\r\n",
        "    val_data = np.vstack((val_data, test_X))\r\n",
        "    val_label = np.hstack((val_label, test_y))\r\n",
        "  print(\"class {} added | train_data: {} | validation_data: {}\".format(i, train_label.shape, val_label.shape))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amlbz3dpUpuK"
      },
      "source": [
        "# Read the Original and augmented train label dataframe\r\n",
        "df = pd.read_csv('/content/drive/MyDrive/SoyabeanWilting/data/TrainAnnotations.csv')\r\n",
        "train_df = pd.DataFrame(train_label, columns=[\"annotation\"])\r\n",
        "\r\n",
        "fig, axes = plt.subplots(1, 2, sharex=True, figsize=(10,5))\r\n",
        "fig.suptitle('Class distribution')\r\n",
        "\r\n",
        "# Plot class distribution before and after augmentation\r\n",
        "sns.countplot(x=\"annotation\", data=df, palette=\"Spectral\", ax=axes[0])\r\n",
        "axes[0].set_title('Before Augmentation')\r\n",
        "sns.countplot(x=\"annotation\", data=train_df, palette=\"Spectral\", ax=axes[1])\r\n",
        "axes[1].set_title('After Augmentation')\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6C9l4x2IRwO-"
      },
      "source": [
        "# Obtain Train and Validation dataset\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((train_data, train_label))\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((val_data, val_label))\n",
        "print(train_dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STOx8f3FRwPF"
      },
      "source": [
        "# All images will be resized to 224 X 224 and cast to 0-1 float format\n",
        "IMG_SIZE = 224 \n",
        "def format_example(image, label):\n",
        "    image = tf.cast(image, tf.float32)\n",
        "    image = (image/255) \n",
        "    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n",
        "    return image, label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8iQ46KCRwPN"
      },
      "source": [
        "train = train_dataset.map(format_example)\n",
        "validation = val_dataset.map(format_example)\n",
        "print(type(train))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ERE-0rT4RwPW"
      },
      "source": [
        "# Define batch size and input image size\n",
        "BATCH_SIZE = 64\n",
        "IMG_SHAPE = (IMG_SIZE,IMG_SIZE,3)\n",
        "\n",
        "train_batches = train.batch(BATCH_SIZE)\n",
        "validation_batches = validation.batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_4DQbHpRwPa"
      },
      "source": [
        "# Check batch shape\n",
        "for image_batch, label_batch in train_batches.take(1):\n",
        "    pass\n",
        "image_batch.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k_S9Z8aMRwPe"
      },
      "source": [
        "# Define Base model as VGG16 initialized with Imagenet weights\n",
        "base_model = tf.keras.applications.VGG16(input_shape=IMG_SHAPE,\n",
        "                                               include_top=False,\n",
        "                                               weights='imagenet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb-UBcF0RwPj"
      },
      "source": [
        "# Check output feature shape of the base model\n",
        "feature_batch = base_model(image_batch)\n",
        "print(feature_batch.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eF6IbVidRwPp"
      },
      "source": [
        "# Make the base model trainable\r\n",
        "base_model.trainable = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgU-AWeLwBzJ"
      },
      "source": [
        "# Fine-tune from this layer onwards\n",
        "fine_tune_at = 15\n",
        "\n",
        "# Freeze all the layers before the `fine_tune_at` layer\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable =  False"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LGC_b6mQRwPu"
      },
      "source": [
        "# Add layers after the base model\n",
        "global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n",
        "feature_batch_average = global_average_layer(feature_batch)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y5ray0YvRwP1"
      },
      "source": [
        "prediction_layer = tf.keras.layers.Dense(5,kernel_regularizer=regularizers.l1_l2(l1=0.01,l2=0.01))\n",
        "prediction_batch = prediction_layer(feature_batch_average)\n",
        "print(prediction_batch.shape) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IAfboUAssMI4"
      },
      "source": [
        "l1 = 0.0013\r\n",
        "l2 = 0.0005\r\n",
        "mom = 0.9\r\n",
        "lr = 0.0001\r\n",
        "drop = 0.6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxuiQ5NyRwP5"
      },
      "source": [
        "model = tf.keras.Sequential([    #,kernel_initializer=initializers.LecunNormal()\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(512, 5, activation=\"elu\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=(3,3)),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "\n",
        "  tf.keras.layers.Dense(512,\n",
        "                        activation='elu',\n",
        "                        kernel_regularizer=regularizers.l1(l1=l1),\n",
        "                        kernel_initializer=initializers.he_normal()),\n",
        "  Dropout(drop), \n",
        "  tf.keras.layers.Dense(256,\n",
        "                        activation='elu',\n",
        "                        kernel_regularizer=regularizers.l1(l1=l1),\n",
        "                        kernel_initializer=initializers.he_normal()),\n",
        "  BatchNormalization(momentum=0.9,epsilon=0.01),\n",
        "  #Dropout(drop), \n",
        "  tf.keras.layers.Dense(128,\n",
        "                        activation='elu',\n",
        "                        kernel_regularizer=regularizers.l1(l1=l1),\n",
        "                        kernel_initializer=initializers.he_normal()),\n",
        "  Dropout(drop), \n",
        "  tf.keras.layers.Dense(64,\n",
        "                        activation='elu',\n",
        "                        kernel_regularizer=regularizers.l1(l1=l1),\n",
        "                        kernel_initializer=initializers.he_normal()),\n",
        "  BatchNormalization(momentum=0.9,epsilon=0.01),\n",
        "  #Dropout(drop), \n",
        "  tf.keras.layers.Dense(32,\n",
        "                        activation='elu',\n",
        "                        kernel_regularizer=regularizers.l1(l1=l1),\n",
        "                        kernel_initializer=initializers.he_normal()),\n",
        "  Dropout(drop), \n",
        "  tf.keras.layers.Dense(16,activation='relu',kernel_regularizer=regularizers.l1(l1=l1)),\n",
        "  tf.keras.layers.Dense(5, activation=\"softmax\"),\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A1TF5J3QRwP_"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "23IjejUDRwP9"
      },
      "source": [
        "model.compile(optimizer=tf.keras.optimizers.Adam(lr=lr,),\n",
        "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
        "              metrics=[tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zrrhxuhmRwQF"
      },
      "source": [
        "len(model.trainable_variables)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7LeygDhsnRkz"
      },
      "source": [
        "w_arr = compute_class_weight('balanced', np.unique(train_label), train_label)\n",
        "weights = {i : w_arr[i] for i in range(5)}\n",
        "weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0PGY1Q8URwQT"
      },
      "source": [
        "H = model.fit(train_data, train_label,\n",
        "\tvalidation_data=(val_data, val_label),\n",
        "  batch_size= BATCH_SIZE,\n",
        "  epochs=80, \n",
        "  class_weight=weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQIbQuY8RwQY"
      },
      "source": [
        "acc = H.history['accuracy']\n",
        "val_acc = H.history['val_accuracy']\n",
        "\n",
        "loss = H.history['loss']\n",
        "val_loss = H.history['val_loss']\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.subplot(2, 1, 1)\n",
        "plt.plot(acc, label='Training Accuracy')\n",
        "plt.plot(val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.ylabel('Accuracy')\n",
        "#plt.ylim([min(plt.ylim()),1])\n",
        "plt.title('Training and Validation Accuracy')\n",
        "\n",
        "plt.subplot(2, 1, 2)\n",
        "plt.plot(loss, label='Training Loss')\n",
        "plt.plot(val_loss, label='Validation Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Cross Entropy')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T_aVl2pPaMSR"
      },
      "source": [
        "import datetime\r\n",
        "\r\n",
        "now = datetime.datetime.now()\r\n",
        "date_time = now.strftime(\"%d.%m.%H:%M:%S\")\r\n",
        "print(\"date and time:\",date_time)\r\n",
        "acc = val_acc[-1]\r\n",
        "acc = round(acc, 4)\r\n",
        "print(acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBAnGw2yQuIF"
      },
      "source": [
        "# serialize model to JSON\r\n",
        "model_json = model.to_json()\r\n",
        "with open(\"../model.json\", \"w\") as json_file:\r\n",
        "    json_file.write(model_json)\r\n",
        "# serialize weights to HDF5\r\n",
        "#model.save_weights(\"model.h5\")\r\n",
        "model.save('../'+str(acc)+\".\"+date_time+'.h5')\r\n",
        "print(\"Saved model to disk\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRSkpZq_xuLr"
      },
      "source": [
        "test_data = x_test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rm8ilHbRRwQt"
      },
      "source": [
        "probability_model = tf.keras.Sequential([model, tf.keras.layers.Softmax()])\n",
        "predictions_test = probability_model.predict(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQk0TtbXyOHB"
      },
      "source": [
        "import csv\n",
        "p0 = 0\n",
        "p1 = 0\n",
        "p2 = 0\n",
        "p3 = 0\n",
        "p4 = 0\n",
        "for i in range(len(test_data)):\n",
        "    if np.argmax(predictions_test[i]) == 0: \n",
        "        p0 += 1\n",
        "    elif np.argmax(predictions_test[i]) == 1: \n",
        "        p1 += 1\n",
        "    elif np.argmax(predictions_test[i]) == 2: \n",
        "        p2 += 1\n",
        "    elif np.argmax(predictions_test[i]) == 3: \n",
        "        p3 += 1\n",
        "    elif np.argmax(predictions_test[i]) == 4: \n",
        "        p4 += 1\n",
        "print(p0,p1,p2,p3,p4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9xopqVwNMi1"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}